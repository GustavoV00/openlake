apiVersion: sparkoperator.k8s.io/v1beta2
kind: SparkApplication
metadata:
  name: spark-test
  namespace: spark-job
spec:
  type: Python
  mode: cluster
  image: localhost:5000/spark-s3:3.5.1
  imagePullPolicy: Always
  mainApplicationFile: s3a://spark-apps/spark-test.py
  sparkVersion: 3.5.1
  
  sparkConf:
    "spark.hadoop.fs.s3a.endpoint": "http://minio.minio:9000"
    "spark.hadoop.fs.s3a.access.key": "minioadmin"
    "spark.hadoop.fs.s3a.secret.key": "minioadmin"
    "spark.hadoop.fs.s3a.path.style.access": "true"
    "spark.hadoop.fs.s3a.fast.upload": "true"
    "spark.hadoop.fs.s3a.impl": "org.apache.hadoop.fs.s3a.S3AFileSystem"
    "spark.hadoop.fs.s3a.connection.ssl.enabled": "false"
    "spark.sql.adaptive.enabled": "true"
    "spark.sql.extensions": "io.delta.sql.DeltaSparkSessionExtension"
    "spark.sql.catalog.spark_catalog": "org.apache.spark.sql.delta.catalog.DeltaCatalog"

  driver:
    labels:
      version: 3.5.1
    cores: 1
    memory: 2g
    serviceAccount: spark-operator-spark
    env:
      - name: AWS_ACCESS_KEY_ID
        value: "minioadmin"
      - name: AWS_SECRET_ACCESS_KEY
        value: "minioadmin"
    securityContext:
      capabilities:
        drop:
        - ALL
      runAsGroup: 185
      runAsUser: 185
      runAsNonRoot: true
      allowPrivilegeEscalation: false
      seccompProfile:
        type: RuntimeDefault
  
  executor:
    labels:
      version: 3.5.1
    instances: 2
    cores: 1
    memory: 2g
    env:
      - name: AWS_ACCESS_KEY_ID
        value: "minioadmin"
      - name: AWS_SECRET_ACCESS_KEY
        value: "minioadmin"
    securityContext:
      capabilities:
        drop:
        - ALL
      runAsGroup: 185
      runAsUser: 185
      runAsNonRoot: true
      allowPrivilegeEscalation: false
      seccompProfile:
        type: RuntimeDefault